langchain4j.open-ai.chat-model.base-url=xxx
langchain4j.open-ai.chat-model.api-key=xxx
#langchain4j.open-ai.chat-model.model-name=gpt-3.5-turbo-16k
langchain4j.open-ai.chat-model.model-name=qwen-max
langchain4j.open-ai.chat-model.max-tokens=256
langchain4j.open-ai.chat-model.temperature=0.0
langchain4j.open-ai.chat-model.timeout=PT60S
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true

#llm stream config
langchain4j.open-ai.streaming-chat-model.base-url=xxx
langchain4j.open-ai.streaming-chat-model.api-key=xxx
langchain4j.open-ai.streaming-chat-model.model-name=gpt-4-1106-preview
langchain4j.open-ai.streaming-chat-model.max-tokens=768
langchain4j.open-ai.streaming-chat-model.temperature=0.0
langchain4j.open-ai.streaming-chat-model.timeout=PT60S
langchain4j.open-ai.streaming-chat-model.log-requests=true
langchain4j.open-ai.streaming-chat-model.log-responses=true

logging.level.dev.langchain4j=DEBUG
logging.level.dev.ai4j.openai4j=DEBUG